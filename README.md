# Kaggle Q&A Google Labeling competition
![Python 2.7](https://img.shields.io/badge/python-2.7-blue.svg) 
![Python 3.6](https://img.shields.io/badge/python-3.3-blue.svg) 
![Spyder 4.1.3](https://img.shields.io/badge/spyder-4.1.3-black) 
![Numpy 1.12.1](https://img.shields.io/badge/numpy-1.12.1-yellow.svg) 
![Matplotlib 2.1.2](https://img.shields.io/badge/matplotlib-2.1.2-blue.svg) 
![Keras 2.3.1](https://img.shields.io/badge/keras-2.3.1-red) 
![Tensorflow 2.1.0](https://img.shields.io/badge/tensorflow-2.1.0-orange) 
![Scikit-image 0.16.2](https://img.shields.io/badge/scikit--image-0.16.2-yellowgreen)  


Code which scored top 16% result in [Google QUEST Q&A Labeling](https://www.kaggle.com/c/google-quest-challenge/overview).  
Basing on algorithm developed by [akensert](https://www.kaggle.com/akensert/quest-bert-base-tf2-0).  
My changes consisted of ...

## Motivation

To practice deep learning in keras enviroment, transfer learning.

## Installation

Python is a requirement (Python 3.3 or greater, or Python 2.7). Recommended enviroment is Anaconda distribution to install Python and Spyder (https://www.anaconda.com/download/).

__Installing dependencies__  
To install can be used pip command in command line.  
  
	pip install -r requirements.txt

__Installing python libraries__  
Exemplary commands to install python libraries:
 
	pip install numpy  
	pip install pandas  
	pip install xgboost  
	pip install seaborn 

__Running code__  
Everything is executed from file main.py. Go to directory where code is downoladed and run a command: 

	py main.py
	
Additional requirement is Tensorflow GPU support. Process of configuiring it is described [here](https://www.tensorflow.org/install/gpu).

## Code examples



## Key Concepts
__Deep Learning__

__Transfer Learning__
  
## Model architecture  


## Results

## Summary  

## Resources
[1] Federico Baldassarre, Diego González Morin, Lucas Rodés-Guirao, *Deep Koalarization: Image Colorization using CNNs and Inception-Resnet-v2*,
(https://arxiv.org/abs/1712.03400)  
[2] Richard Zhang, Phillip Isola, Alexei A. Efros, *Colorful Image Colorization*,
(https://arxiv.org/abs/1603.08511)  
[3] Gustav Larsson, Michael Maire, Gregory Shakhnarovich, *Learning Representations for Automatic Colorization*,
(https://arxiv.org/abs/1603.06668)  
[4] Satoshi Iizuka, Edgar Simo-Serra, Hiroshi Ishikawa, *Let there be Color!: Joint End-to-end Learning of Global and Local Image Priors 
for Automatic Image Colorization with Simultaneous Classification*,
(https://www.researchgate.net/publication/305218105_Let_there_be_color_joint_end-to-end_learning_of_global_and_local_image_priors_for_automatic_image_colorization_with_simultaneous_classification)  
[5] Dipanjan Sarkar, Raghav Bali, Tamoghna Ghosh, *Hands-On Transfer Learning with Python: Implement advanced deep learning and neural network models using TensorFlow and Keras*
[6] https://becominghuman.ai/auto-colorization-of-black-and-white-images-using-machine-learning-auto-encoders-technique-a213b47f7339  
[7] https://fairyonice.github.io/Color-gray-scale-images-and-manga-using-deep-learning.html  
[8] https://towardsdatascience.com/review-xception-with-depthwise-separable-convolution-better-than-inception-v3-image-dc967dd42568